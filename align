#!/Users/remy/Applications/PyCharmProjects/fehrest/venv/bin/python
# -*- coding: utf-8 -*-

import argparse
import pickle
from collections import defaultdict
from index import InvertedIndex
from pysam import FastxFile


def align(p, d, idx):
    k = inverted_index.k
    mod = len(p) % k
    if mod != 0:
        print("An extra partition of length {} cannot not be seeded".format(mod))
    offsets = defaultdict(list)
    seeds = set()
    # Seed
    # For each partition
    for i in range(0, d + 1):
        # Employ PHP strategy
        shift = i * inverted_index.k
        kmer = p[shift:shift + inverted_index.k]
        # For each contig of genome
        for contig in inverted_index.index:
            anchors = inverted_index.query(kmer.encode(), contig)
            if anchors:
                for anchor in anchors:
                    if anchor-shift < 0:
                        continue  # fell off the LHS of the genome
                    if anchor-shift+len(p) > idx.ref.get_reference_length(contig):
                        continue  # fell off the RHS of the genome
                    if anchor-shift >= 0:
                        seeds.add((contig, anchor-shift))
    # Extend
    for seed in seeds:
        hit = idx.ref.fetch(seed[0], seed[1], seed[1]+len(p))
        hamming_distance = [a != b for (a, b) in zip(p, hit)].count(True)
        if hamming_distance <= d and (seed, hamming_distance) not in offsets[contig]:
            offsets[contig].append((seed[1], hamming_distance))
    return offsets


def summarize_alignments(alignment_lst):
    counts = {0: [], 1: [], 2: [], 3: [], 4: []}
    for aln in alignment_lst:
        for contig in aln:
            matches = aln[contig]
            for match in matches:
                if match[1] == 0:
                    counts[0].append(match[0])
                elif match[1] == 1:
                    counts[1].append(match[0])
                elif match[1] == 2:
                    counts[2].append(match[0])
                elif match[1] == 3:
                    counts[3].append(match[0])
                elif match[1] == 4:
                    counts[4].append(match[0])
    print(counts)


def best_alignments(alignment_lst):
    counts = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}
    for aln in alignment_lst:
        for contig in aln:
            matches = aln[contig]
            best_match = sorted(matches, key=lambda x: x[1])[0]
            if best_match[1] == 0:
                counts[0] += 1
            elif best_match[1] == 1:
                counts[1] += 1
            elif best_match[1] == 2:
                counts[2] += 1
            elif best_match[1] == 3:
                counts[3] += 1
            elif best_match[1] == 4:
                counts[4] += 1
    print(list(counts.values()))


if __name__ == "__main__":
    # Parse command
    parser = argparse.ArgumentParser()
    parser.add_argument("-x", "--index", required=True, help="The path to your index file")
    parser.add_argument("-fq", "--fastx", required=True, help="Path to your sequencing reads")
    parser.add_argument("-d", "--distance", default=4, help="Maximum distance of P from T")
    parser.add_argument("-db", "--debug", default=False, help="Some extra printing for debugging")
    args = parser.parse_args()

    # Prepare index
    index_dump = pickle.load(open(args.index, 'rb'))
    inverted_index = InvertedIndex(index_dump[2], index_dump[0])
    inverted_index.index = index_dump[1]

    debug = args.debug
    if debug:
        print("Value of k is {}".format(index_dump[0]))

    # Perform alignment
    # Sample human patterns to search for
    # p1 = "TGGATGTGAAATGAGTCAAG"
    # p2 = "GGGTGGGGGGAGTTTGCTCC"
    reads = FastxFile(args.fastx)
    alignments = []
    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A'}
    d = int(args.distance)
    for read in reads:
        if debug:
            print(len(read.sequence))
        # |P| cannot be < k
        assert len(read.sequence) > index_dump[0]
        alignment = align(read.sequence, d, inverted_index)
        alignments.append(alignment)
        # rc_alignment = align(read.sequence.translate(read.sequence.maketrans(complement)), 3, inverted_index)
        # alignments.append(rc_alignment)

    # Some Summaries
    # summarize_alignments(alignments)
    best_alignments(alignments)
