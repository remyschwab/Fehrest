#!venv/bin/python
# -*- coding: utf-8 -*-

"""This module will instantiate an Inverted Index from disk and
use it to search for reads from a FASTQ file"""

import argparse
import os
import pickle
from collections import defaultdict
from pysam import FastxFile
from index import InvertedIndex
from base2base_aln import hamming_distance


def partition(pattern, dist):
    """Employ Pigeon-Hole-Principle to partition the pattern into non-overlapping substrings"""
    k = int(len(pattern) / (dist + 1))
    mod = len(pattern) % k
    partitions = []
    for i in range(0, dist + 1):
        shift = i * k
        kmer = pattern[shift: shift + k]
        partitions.append((kmer, shift))
    if mod != 0:
        print("An extra partition of length {} cannot not be seeded".format(mod))
    return partitions


def seed(pattern, partitions, idx):
    """Query the partitions for anchors to the genome"""
    contig = None
    seeds = set()
    contigs = [os.path.splitext(ctg)[0] for ctg in os.listdir(idx.dir)]
    contigs.remove('meta_info')
    for kmer, shift in partitions:
        for contig in contigs:
            contig_length = idx.ref.get_reference_length(contig)
            anchors = idx.query(kmer.encode(), contig)
            if anchors:
                for anchor in anchors:
                    if anchor - shift < 0:
                        continue  # fell off the LHS of the genome
                    if anchor - shift + len(pattern) > contig_length:
                        continue  # fell off the RHS of the genome
                    seeds.add((contig, anchor - shift))
    return seeds


def extend(pattern, anchors, idx, dist):
    """Extend seeds by using base-to-base comparison"""
    offsets = defaultdict(list)
    for contig, anchor in anchors:
        hit = idx.ref.fetch(contig, anchor, anchor + len(pattern))
        h_dist = hamming_distance(pattern, hit, dist)
        if h_dist <= dist and (anchor, hamming_distance) not in offsets[contig]:
            offsets[contig].append((anchor, h_dist))
    return offsets


def summarize_alignments(alignment_lst):
    """Print out how many reads had an alignment
    at each distnace from the the Text"""
    counts = {0: [], 1: [], 2: [], 3: [], 4: []}
    for aln in alignment_lst:
        for contig in aln:
            matches = aln[contig]
            for match in matches:
                if match[1] == 0:
                    counts[0].append(match[0])
                elif match[1] == 1:
                    counts[1].append(match[0])
                elif match[1] == 2:
                    counts[2].append(match[0])
                elif match[1] == 3:
                    counts[3].append(match[0])
                elif match[1] == 4:
                    counts[4].append(match[0])
    print(counts)


def best_alignments(alignment_lst):
    """How many reads had their best alignment at each distnace from the text"""
    counts = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}
    for aln in alignment_lst:
        for contig in aln:
            matches = aln[contig]
            best_match = sorted(matches, key=lambda x: x[1])[0]
            if best_match[1] == 0:
                counts[0] += 1
            elif best_match[1] == 1:
                counts[1] += 1
            elif best_match[1] == 2:
                counts[2] += 1
            elif best_match[1] == 3:
                counts[3] += 1
            elif best_match[1] == 4:
                counts[4] += 1
    print(list(counts.values()))


if __name__ == "__main__":
    # Parse command
    PARSER = argparse.ArgumentParser()
    PARSER.add_argument(
        "-x", "--index", required=True, help="The path to your index file"
    )
    PARSER.add_argument(
        "-i", "--reads", required=True, help="Path to your sequencing reads"
    )
    PARSER.add_argument(
        "-d", "--distance", default=4, help="Maximum distance of P from T"
    )
    PARSER.add_argument(
        "-db", "--debug", default=False, help="Some extra printing for debugging"
    )
    ARGS = PARSER.parse_args()

    # Load Index from Disk
    INDEX_DUMP = pickle.load(open(ARGS.index+'/meta_info', "rb"))
    INVERTED_INDEX = InvertedIndex(INDEX_DUMP[0], INDEX_DUMP[1])
    INVERTED_INDEX.dir = ARGS.index

    DEBUG = ARGS.debug
    if DEBUG:
        print("Value of k is {}".format(INDEX_DUMP[1]))

    # Perform alignment
    # Sample human patterns to search for
    READS = FastxFile(ARGS.reads)
    ALIGNMENTS = []
    DISTANCE = int(ARGS.distance)
    for read in READS:
        if DEBUG:
            print(len(read.sequence))
        # |P| cannot be < k
        assert len(read.sequence) > INDEX_DUMP[1]
        parts = partition(read.sequence, DISTANCE)
        gseeds = seed(read.sequence, parts, INVERTED_INDEX)
        alignment = extend(read.sequence, gseeds, INVERTED_INDEX, DISTANCE)
        ALIGNMENTS.append(alignment)

    # Some Summaries
    # summarize_alignments(alignments)
    best_alignments(ALIGNMENTS)
